---
title: "COVID19 Mortality rate prediction. IML '20 Homework 3."
author: "Åukasz Grad"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r, include=F}
library(tidyverse)
library(DALEX)
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(caret)
library(glmnet)
library(randomForest)
library(xgboost)
library(splines)
library(data.table)

theme_set(theme_economist())
```

Read and show raw updated data.

Source: https://github.com/beoutbreakprepared/nCoV2019/blob/master/latest_data/latestdata.csv

```{r, include=F}
covid = read_csv('data/latestdata.csv')
```

```{r}
covid %>% head()
```

We have a lot of missing values and data in general is messy. The column of interest is "outcome"

```{r}
covid %>%
    summarise_all(~ mean(is.na(.)))
```

Some improvement (but only for modelling) in positive cases tally - 200

```{r}
# A tiny bit of cheating to increase positive sample size
death_vals = c('death', 'died',
               'treated in an intensive care unit (14.02.2020)',
               'critical condition, intubated as of 14.02.2020')
covid %>% filter(outcome %in% death_vals)
```

```{r, include=F}
clean_string <- function(string){
    temp <- tolower(string)
    temp <- stringr::str_replace_all(temp,"[^a-zA-Z\\s]", " ")
    temp <- stringr::str_replace_all(temp,"[\\s]+", " ")
    temp <- stringr::str_split(temp, " ")[[1]]
    indexes <- which(temp == "")
    if(length(indexes) > 0){
      temp <- temp[-indexes]
    } 
    return(temp)
}
```

Let's see the most common early symptoms

```{r}
symptoms_data = lapply(covid$symptoms, clean_string)
symptoms_all = Reduce(c, symptoms_data)
symptoms_all_sorted = sort(table(symptoms_all), decreasing = T)
symptoms_all_sorted[1:15]
```

Seems like new data comes from Philippines

```{r}
covid %>% 
    filter(outcome %in% death_vals) %>%
    ggplot(aes(country)) +
    geom_bar() +
    coord_flip()
```

Prepare clean dataset.

```{r}
frequent_countries = c('china', 'united states', 'philippines')
frequent_symptoms = c('pneumonia|pneumonitis', 'fever', 
                      'cough', 'sore throat')

covid_train = covid %>%
    mutate(
        outcome = ifelse(outcome %in% death_vals, 'dead', 'recovered'),
        country = ifelse(tolower(country) %in% frequent_countries, country, 'other'),
        in_wuhan = !as.logical(`wuhan(0)_not_wuhan(1)`),
        age = ifelse(str_detect(age, "[:digit:]{2}-[:digit:]{2}"),
                     0.5 * as.numeric(str_sub(age, 1, 2)) + 0.5 * as.numeric(str_sub(age, 3, 4)),
                     as.numeric(age)),
        sex = tolower(sex),
        chronic_disease = ifelse(is.na(chronic_disease_binary),
                                 'unknown',
                                 ifelse(chronic_disease_binary == '1', '1', '0'))
    ) %>%
    select(age, sex, country, chronic_disease, outcome, in_wuhan, symptoms) %>%
    filter(!is.na(age)) %>%
    filter(!is.na(sex))

for (symptom in frequent_symptoms) {
    covid_train[symptom] = str_detect(symptom, covid_train$symptoms)
    covid_train[symptom][is.na(covid_train[symptom])] = F
}

covid_train = covid_train %>% select(-symptoms)
covid_train = covid_train %>%
    mutate_if(is.logical, as.factor)

covid_train %>% head
```

```{r, include=F}
set.seed(1)
covid_train = covid_train %>% select(-in_wuhan)
covid_train = covid_train[sample(1:nrow(covid_train), size = nrow(covid_train), replace = F, ),]
```

# 5a) Train a second model (of any class, neural nets, linear, other boosting) 

Create simple dataset split and fit Logistic Lasso with CV

```{r}
covid_train = covid_train %>%
    mutate_if(is.character, as.factor)

train_mask = caret::createDataPartition(covid_train$outcome, p = 0.7)[[1]]
data_train = covid_train[train_mask,]
data_valid = covid_train[-train_mask,]

xlevs_train = data_train %>% select(-outcome)
xlevs <- lapply(xlevs_train[,sapply(xlevs_train, is.factor), drop = F], function(j){
    levels(j)
})
```

```{r}
pos = function(x, s, u = NULL) {
    x = ifelse(x > s, x - s, 0)
    if (!is.null(u))
        x = ifelse(x > (u - s), u - s, x)
    x
}

dtrain = model.matrix(~ age + pos(age, 50) + . - 1, 
                      data = data_train %>% select(-outcome))
dvalid = model.matrix(~ age + pos(age, 50) +  . - 1,
                      data = data_valid %>% select(-outcome))
cv_glmnet = cv.glmnet(dtrain, data_train$outcome == 'dead', family = 'binomial', nfolds = 5, 
                   type.measure = 'deviance', keep = TRUE)
plot(cv_glmnet)
```

Coefficients for best model

```{r}
best_ind = which(cv_glmnet$lambda == cv_glmnet$lambda.min)
beta = cv_glmnet$glmnet.fit$beta[, best_ind]
beta
```

```{r, include = F}
grid_default <- expand.grid(
    nrounds = 25,
    max_depth = 3,
    eta = 0.3,
    gamma = 0,
    colsample_bytree = 1,
    min_child_weight = 1,
    subsample = 1
)

ctrl <- trainControl(method = "cv", 
                     number = 5,                        
                     allowParallel = TRUE)

bst = caret::train(dtrain, data_train$outcome %>% as.factor,
                      method = 'xgbTree',
                      trControl = ctrl,
                      tuneGrid = grid_default,
                      verbose=TRUE) 
```

Log-odds histogram for Logistic Lasso on validation data

```{r}
pred_data = tibble(y = data_valid$outcome == 'dead', 
       pred_link = predict(cv_glmnet, dvalid, type='link', s = 'lambda.min'),
       pred = predict(cv_glmnet, dvalid, type='response', s = 'lambda.min'))
pred_data %>%
    ggplot(aes(pred_link, fill = y)) +
    geom_histogram(stat = 'density', alpha = 0.5, position = 'identity')
```

Train a simple Logistic Regression on single split - had some troubles to make GLMNET work with LIME

```{r}
lrm = glm(outcome == 'dead' ~ age + sex + country +
                              fever + chronic_disease,
          family = 'binomial', data = data_train)
summary(lrm)
```

#1. For the selected data set, train a predictive model

Fit XGBoost model with monotonicity constraint for age with the same dataset as Logistic Lasso

```{r}
dtrain_xgb = model.matrix(~ . - 1, 
                      data = data_train %>% select(-outcome))
dvalid_xgb = model.matrix(~ . - 1,
                      data = data_valid %>% select(-outcome))

bst  = xgboost(data = dtrain_xgb, label = ifelse(data_train$outcome == 'dead', 1, 0), max_depth = 3, 
               eta = 0.3, nrounds = 35, nthread = 2, colsample_bytree = 0.5,
               objective = "binary:logistic", scale_pos_weight = 1, eval_metric = 'logloss',
               monotone_constraints = '(1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)')
```

Log-odds histogram for XGBoost model on validation data

```{r}
logit <- function(x) log(x / (1 - x))

pred_data = tibble(y = data_valid$outcome == 'dead', 
       pred = predict(bst, dvalid_xgb, type='prob'))
pred_data %>%
    ggplot(aes(logit(pred), fill = y)) +
    geom_histogram(stat = 'density', alpha = 0.5, position = 'identity')
```

```{r, include=F}
sigmoid = function(x) 1 / (1 + exp(x))
logit = function(x) log(x / (1 - x))

th = sigmoid(1) * 100
th
```

Use DALEX library to create explainers :-) and show validation metrics - cutoff selected manually, but it's not that important. 

```{r, include=F}
th = 30

lrm_explain = DALEX::explain(lrm, data = data_valid %>% select(-outcome), 
                             y = data_valid$outcome == 'dead', 
                             type = 'classification', label = 'GLM', 
                             predict_function = function(m, d) yhat(m, d) * 100)

xgb_predict = function(model, data) {
    data = model.matrix(~ . - 1, data = data, xlev = xlevs)
    predict(model, data, type = 'prob') * 100
}
xgb_explain = DALEX::explain(bst, data = data_valid %>% select(-outcome),
                             y = data_valid$outcome == 'dead', 
                             type = 'classification', label = 'XGB',
                             predict_function = xgb_predict)

glmnet_predict = function(model, data) {
    data = model.matrix(~ age + pos(age, 50) + . - 1, data = data, xlev = xlevs)
    predict(model, data, type = 'response', s = 'lambda.min')[, 1] * 100
}

cv_glmnet_explain = DALEX::explain(cv_glmnet, data = data_valid %>% select(-outcome),
                                    y = data_valid$outcome == 'dead', 
                                    type = 'classification', label = 'GLMNET',
                                    predict_function = glmnet_predict)
```

Looks like all the models perform much better on validation data than last time.

Seems like newly added positive cases are easier to separate, though more training samples also helps.

```{r}
lrm_perf = DALEX::model_performance(lrm_explain, cutoff = th)
xgb_perf = DALEX::model_performance(xgb_explain, cutoff = th)
cv_glmnet_perf = DALEX::model_performance(cv_glmnet_explain, cutoff = th)
lrm_perf
xgb_perf
cv_glmnet_perf
```

```{r}
p1 <- plot(cv_glmnet_perf, xgb_perf, lrm_perf, geom = "roc")
p2 <- plot(cv_glmnet_perf, xgb_perf, lrm_perf, geom = "lift")

library(patchwork)
p1 + p2
```

#2. for some selected observation from this dataset, calculate the model predictions for model (1)

```{r}
example_ind = 1
example = data_valid[example_ind, ]
example
```

```{r}
xgb_predict(bst, example %>% select(-outcome))
```

XGBoost model predicts < 1% mortality rate for a 71 year old woman, without any known symptoms. Seems 
pretty low, nevertheless it is correct.

#3. for an observation selected in (2), calculate the decomposition of model prediction using LIME / live / lime / localModel or similar technique

```{r, include=F}
library(localModel)

plot_decomposition <- function(explainer, observation, type = 'break_down_interactions') {
    ex = DALEX::variable_attribution(explainer, 
                                     new_observation = observation, 
                                     type = type)
    p = plot(ex)
    p = p + ggtitle('Mortality rate COVID 19')
    if (type != 'shap') {
        p = p + scale_y_continuous(expand = expand_scale(c(0, 0.4)), name = NULL)
        p$data$right_side = pmax(p$data$prev, p$data$cumulative)
        p$data$pretty_text = paste(p$data$pretty_text, '%')
    }
    p
}


plot_lime <- function(explainer, observation, size = 1000L, seed = 1) {
    local_model = individual_surrogate_model(explainer, observation, size = size, seed = seed)
    plot(local_model)
    local_model
}
```

```{r, include = F}
library(lime)

xgb_prep <- function(data) {
    dmatrix = model.matrix(~ age + pos(age, 50) + . - 1, data = data, xlev = xlevs)
    return(xgb.DMatrix(dmatrix))
}

predict_model.cv.glmnet <- function(x, data, type, ...) {
  if (type == 'raw') {
      type = 'class'
  } else {
      type = 'response'
  }
  print(sum(is.na(data)))
  data = model.matrix(~ age + pos(age, 50) + . - 1, data = data, xlev = xlevs)
  res <- predict(x, newdata = data, type, s = 'lambda.min')
  res
}

predict_model.glm <- function(x, data, type, ...) {
  res <- predict(x, newdata = data, type = 'response', ...)
  if (type == 'raw') {
      ind = ifelse(res > 0.5, 2, 1)
      res = data.frame(Response = names(res)[ind], stringsAsFactors = F)
  } else {
      res = as.data.frame(cbind(1 - res, res), check.names = F)
       colnames(res) = c('recovered', 'dead')
  }
  res
}

model_type.cv.glmnet <- function(x, ...) 'classification'
model_type.glm <- function(x, ...) 'classification'
```

```{r, warning=F}
lime_xgb  = lime::lime(as.data.table(dvalid_xgb), model = bst)
explanation <- lime::explain(as.data.table(dvalid_xgb[example_ind:(example_ind + 1),]), 
                             lime_xgb, n_labels = 1, n_features = 3, n_permutations = 10000)
plot_features(explanation, cases = 1)
```

LIME selects sex and age as the two most important factors. Female gender decreases mortality rate (positive
impact for 'recovered' class here) and age > 61 yo, as expected, increases mortality rate and is crucial
especially in older group.

# 4. compare LIME decompositions for different observations in the dataset. How stable are these explanations?

```{r}
xgb_preds = xgb_predict(bst, data_valid %>% select(-outcome))
low_examples = c(974, 2525)
med_examples = c(2195, 3313)
high_examples = c(101, 2657)
```

Low mortality examples:

```{r}
explanation <- lime::explain(as.data.table(dvalid_xgb[low_examples,]), 
                             lime_xgb, n_labels = 1, n_features = 3,
                             n_permutations = 10000)
plot_features(explanation)
```

Medium mortality examples:

```{r}
explanation <- lime::explain(as.data.table(dvalid_xgb[med_examples,]), 
                             lime_xgb, n_labels = 1, n_features = 3, n_permutations = 10000)
plot_features(explanation)
```

High mortality examples:

```{r}
explanation <- lime::explain(as.data.table(dvalid_xgb[high_examples,]), 
                             lime_xgb, n_labels = 1, n_features = 3, n_permutations = 10000)
plot_features(explanation)
```

For all risk groups, we can see that LIME select age and gender as the most influential variables. Age increases
mortality rate in older group. However, in case of gender, we can observe a discrepancy. For example, in the
two examples from high risk group female sex increases mortality in case 2, and in case 1 male gender
increases it also.

One thing to notice is that XGBoost doesn't select `chronic_disease` as important factor in any of the above.

Also, the quality of local model fit `Explanation Fit` - measured with $R^2$ shows that the quality of
approximation increases for high mortality groups. E.g. for low mortality groups the fit is not much better than random.

#5 find an observation for which LIME attributions are different between the models

```{r}
example_ind = 1440
explanation <- lime::explain(as.data.table(dvalid_xgb[example_ind:(example_ind + 1),]), 
                             lime_xgb, n_labels = 1, n_features = 3, 
                             n_permutations = 10000)
plot_features(explanation, cases = 1)
```


```{r}
lime_lrm  = lime::lime(data_valid, model = lrm)
explanation <- lime::explain(data_valid[example_ind:(example_ind + 1),], 
                             lime_lrm, n_labels = 1, n_features = 3, 
                             n_permutations = 10000)
plot_features(explanation, cases = 1)
```

We can see that for an older person from China with chronic_disease present, both models predict high mortality
rate, but Logistc Regression model selects `chronic_disease` and `age` features as the most impactful. XGBoost also selects `age` but in addition gives high importance to `gender`.

Whats interesting, is that the local approximation is much better for XGBoost model than in case of linear GLM,
which may suggest that dychotomized `age` variable significantly reduces the goodness of fit.