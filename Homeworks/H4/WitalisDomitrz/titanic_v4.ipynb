{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMSYI5kn9V69"
   },
   "source": [
    "# CP for explaining prediction on the Titanic dataset\n",
    "\n",
    "author: Witalis Domitrz <witekdomitrz@gmail.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CP profiles for different observations comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real value:\n",
      "              Survived\n",
      "PassengerId          \n",
      "1000              0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"660\"\n",
       "            height=\"550\"\n",
       "            src=\"_plot_files/plots5.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f99fd0a6d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real value:\n",
      "              Survived\n",
      "PassengerId          \n",
      "1006              1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"660\"\n",
       "            height=\"550\"\n",
       "            src=\"_plot_files/plots6.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f99f9c3cf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the selected two observations the model behaves very differently when looking at the \"Age\" parameter. For the first observation - a male in the third class whose fare is 8.7£, embarked in Southampton - there is a gap between the kids and the adults. The kids are very likely to survive and the adults will most likely die. There are some minor fluctuations, but those are almost negligible compared with the huge (bigger than 80%) \"adulthood gap\". On the other hand for the second observation - a female in the first class whose fare was 221.8£, embarked in the same city - the age do have a positive impact - those older than 30 almost certainly survived and younger people with the same other parameters are from ~10% up to ~20% more likely to die. It is strange for me that the model predicts that the very young children were more likely to die when having all other parameters as in the first observation then as in the second one. Those two observations have almost the same (with the respect to the translation) CP profile of the \"SibSp\" variable - the number of the siblings. The fare profiles are also different, but they do share the same property - the fare above £250 has the same impact as exactly £250. The differences in the \"Fare\" and \"Age\" CP profiles might be caused by the different classes of the two observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Differences between CP profiles of the same observation for two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real value:\n",
      "              Survived\n",
      "PassengerId          \n",
      "895               0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"660\"\n",
       "            height=\"550\"\n",
       "            src=\"_plot_files/plots7.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f99f9ca4ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real value:\n",
      "              Survived\n",
      "PassengerId          \n",
      "895               0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"660\"\n",
       "            height=\"550\"\n",
       "            src=\"_plot_files/plots8.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f99f9c3e4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those two models predict very differently given the selected observation. The first model predict correctly and the second one does not. We can clearly see that the profile of the \"Age\" is much more reasonable for the first model and the second one might have overfitted - it has a few very strange and sharp edges. Note that the selected observation is from the test part of data (not the training one) so the overfitting would have negative impact on the accuracy of this prediction. Also the second model is convinced that having no siblings impact the probability of survival for this person positively. It might be a case, but so big difference between 0 and different number of siblings still looks alarming (of course the model might have found some strong dependency which was not noticed by the first model, but the accuracy hints us that it is not the case). The fluctuations of the \"Fare\" profile for the second modle also might mean that these is some overfitting, but still that \"Age\" profile is the strangest one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1k5yb_LDQ0UO"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4_HSH1NZs4s"
   },
   "source": [
    "### Install modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAgb-iHNZr-O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyCeterisParibus in /home/witalis/.local/lib/python3.6/site-packages (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/witalis/.local/lib/python3.6/site-packages (from pyCeterisParibus) (1.18.1)\n",
      "Requirement already satisfied: Flask>=1.0.2 in /home/witalis/.local/lib/python3.6/site-packages (from pyCeterisParibus) (1.1.2)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/witalis/.local/lib/python3.6/site-packages (from pyCeterisParibus) (1.0.1)\n",
      "Requirement already satisfied: click>=5.1 in /home/witalis/.local/lib/python3.6/site-packages (from Flask>=1.0.2->pyCeterisParibus) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/witalis/.local/lib/python3.6/site-packages (from Flask>=1.0.2->pyCeterisParibus) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /home/witalis/.local/lib/python3.6/site-packages (from Flask>=1.0.2->pyCeterisParibus) (1.0.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /home/witalis/.local/lib/python3.6/site-packages (from Flask>=1.0.2->pyCeterisParibus) (2.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/witalis/.local/lib/python3.6/site-packages (from pandas>=0.23.4->pyCeterisParibus) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/witalis/.local/lib/python3.6/site-packages (from pandas>=0.23.4->pyCeterisParibus) (2019.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/witalis/.local/lib/python3.6/site-packages (from Jinja2>=2.10.1->Flask>=1.0.2->pyCeterisParibus) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/witalis/.local/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas>=0.23.4->pyCeterisParibus) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyCeterisParibus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NLkKLWma9wWn"
   },
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzlvCzL3jIGM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-16 18:27:06--  http://students.mimuw.edu.pl/~wd393711/iml/titanic.zip\n",
      "Resolving students.mimuw.edu.pl (students.mimuw.edu.pl)... 2001:6a0:5001:1::3, 193.0.96.129\n",
      "Connecting to students.mimuw.edu.pl (students.mimuw.edu.pl)|2001:6a0:5001:1::3|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34877 (34K) [application/zip]\n",
      "Saving to: ‘titanic.zip’\n",
      "\n",
      "titanic.zip         100%[===================>]  34,06K  --.-KB/s    in 0,1s    \n",
      "\n",
      "2020-04-16 18:27:07 (330 KB/s) - ‘titanic.zip’ saved [34877/34877]\n",
      "\n",
      "Archive:  titanic.zip\n",
      "  inflating: gender_submission.csv   \n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "!wget http://students.mimuw.edu.pl/~wd393711/iml/titanic.zip\n",
    "!unzip -o titanic.zip\n",
    "!rm titanic.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "izJSfphJ94V-"
   },
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFNYvmgVdqxu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "used_columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Survived']\n",
    "X_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "Y_columns = ['Survived']\n",
    "\n",
    "def load_data(fn):\n",
    "    return pd.read_csv(fn).set_index('PassengerId')\n",
    "\n",
    "def to_array(data):\n",
    "    return pd.get_dummies(data).astype(dtype='float32')\n",
    "\n",
    "def data_preprocessing():\n",
    "    global train, test\n",
    "    train = load_data('./train.csv')\n",
    "    test = load_data('./gender_submission.csv').join(load_data('./test.csv'))  \n",
    "\n",
    "    train['is_train'] = True\n",
    "    test['is_train'] = False\n",
    "    data = pd.concat([train, test])\n",
    "\n",
    "    # Replace missing values with mean\n",
    "    data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "    # Split test and train\n",
    "    train, test = data[data['is_train']], data[data['is_train'] == False]\n",
    "\n",
    "    # No unused columns\n",
    "    train, test = train[used_columns], test[used_columns]\n",
    "\n",
    "    train, test = to_array(train), to_array(test)\n",
    "data_preprocessing()\n",
    "\n",
    "\n",
    "def split_to_x_y(data):\n",
    "    return to_array(data[X_columns]), to_array(data[Y_columns])\n",
    "\n",
    "def get_data():\n",
    "    return split_to_x_y(train), split_to_x_y(test)\n",
    "\n",
    "def unlabel_data(*sets):\n",
    "    return ((part.values for part in subset) for subset in sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4GokLUvsTxS5"
   },
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCQ1vW8cP_3R"
   },
   "source": [
    "## 1.\n",
    "For the selected data set, train at least one tree-based ensemble model (random forest, gbm, catboost or any other boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPyw7BqeQ5C9"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier as Model\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HuVgwX6GR6Fh"
   },
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPTe8gNdRZME"
   },
   "outputs": [],
   "source": [
    "model = Model(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
    "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
    "              nthread=None, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8m1RThxnR8eQ"
   },
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ln7FE5tgRaZ3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=1, nthread=1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=0, silent=None,\n",
       "              subsample=1, tree_method=None, validate_parameters=False,\n",
       "              verbosity=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y.values[::,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aT8Ht9m2R-sL"
   },
   "source": [
    "### Check the first model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2A6B7XAWR-Es",
    "outputId": "01f2631f-cc7c-4d9b-8dcc-9cd34df9b78e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the first model: 0.8827751196172249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "test_pred = model.predict(test_x)\n",
    "test_accuracy1 = accuracy_score(test_y, [round(value) for value in test_pred])\n",
    "print(\"Test accuracy of the first model: {}\".format(test_accuracy1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqXfjXroQIVZ"
   },
   "source": [
    "## 2.\n",
    "for some selected observation from this dataset, calculate the model predictions for model (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t38TV1R4U_9N"
   },
   "source": [
    "### Select an observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLrwuAZAfy5J"
   },
   "outputs": [],
   "source": [
    "def select_an_observation(id):\n",
    "    obs = test.loc[[id]]\n",
    "    x, y = split_to_x_y(obs)\n",
    "    return (x, y), obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZ0Vt461XGF4"
   },
   "outputs": [],
   "source": [
    "i2 = 894\n",
    "(x2, y2), obs2 = select_an_observation(i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtYtGMgUfum2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass   Age  SibSp  Parch    Fare  Survived  Sex_female  \\\n",
       "PassengerId                                                             \n",
       "894             2.0  62.0    0.0    0.0  9.6875       0.0         0.0   \n",
       "\n",
       "             Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "PassengerId                                                \n",
       "894               1.0         0.0         1.0         0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdOzt1DKVCzP"
   },
   "source": [
    "### Calculate the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0barI6ZMVKce",
    "outputId": "07f7c0ed-1fb8-4b4d-e13a-54c6948adffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model preadictet that this person would survive with probability: 0.10084572 and the truth is: 0.0\n"
     ]
    }
   ],
   "source": [
    "pred2 = model.predict_proba(x2)\n",
    "print(\"The model preadictet that this person would survive with probability:\", pred2[0][1], \"and the truth is:\", y2.values[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tW01SzPfQFSy"
   },
   "source": [
    "## 3.\n",
    "for an observation selected in (2), calculate the decomposition of model prediction using Ceteris paribus / ICE profiles (packages for R: DALEX, ALEPlot, ingredients, packages for python: pyCeterisParibus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLOmBr3HY4zr"
   },
   "source": [
    "### Use pyCeterisParibus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_ieoLbqYymD"
   },
   "outputs": [],
   "source": [
    "from ceteris_paribus.explainer import explain as Explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5XEqJE8gM18"
   },
   "source": [
    "### Create an explainer function using Ceteris Paribus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjqyDiLZgPFp"
   },
   "outputs": [],
   "source": [
    "from ceteris_paribus.profiles import individual_variable_profile\n",
    "from ceteris_paribus.plots.plots import plot_notebook\n",
    "from collections.abc import Iterable\n",
    "# I have selected the variables based on the LIME explanations from the prievous week\n",
    "DEFAULT_SELECTED_VARIABLES=['Fare', 'Age', 'SibSp']\n",
    "def explain(ids, selected_variables=DEFAULT_SELECTED_VARIABLES, model=model):\n",
    "    # Create an explainer\n",
    "    explainer = Explainer(model, variable_names=test_x.columns, data=test_x, y=test_y.columns, predict_function=lambda X: model.predict_proba(X)[::,1], label=str(model))\n",
    "    def helper(i):\n",
    "        ((x, y), _) = select_an_observation(i)\n",
    "        print(\"Real value:\\n\", y)\n",
    "        # Ceteris Paribus\n",
    "        cp = individual_variable_profile(explainer, x.values[0], y.values[0])\n",
    "        plot_notebook(cp, selected_variables=selected_variables)\n",
    "    \n",
    "    # Support single value not a lise\n",
    "    ids = ids if isinstance(ids, Iterable) else [ids]\n",
    "    \n",
    "    for i in ids:\n",
    "        helper(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1vHd4NNJfStP"
   },
   "source": [
    "### Explain using Ceteris Paribus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "colab_type": "code",
    "id": "HBwsIrKIfgNi",
    "outputId": "96588a1d-3560-4b2f-b194-ffa0f477bfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real value:\n",
      "              Survived\n",
      "PassengerId          \n",
      "894               0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"660\"\n",
       "            height=\"550\"\n",
       "            src=\"_plot_files/plots0.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f99fd09f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i3 = i2\n",
    "explain(i3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ky9lTN88QGMO"
   },
   "source": [
    "## 4.\n",
    "find two observations in the data set, such that they have different CP profiles (e.g. model response is growing with age for one observations and lowering with age for another). Note that you need to have model with interactions to have such differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nj_drW1yflhU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real value:\n",
      "              Survived\n",
      "PassengerId          \n",
      "1000              0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"660\"\n",
       "            height=\"550\"\n",
       "            src=\"_plot_files/plots1.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f99fd86fa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real value:\n",
      "              Survived\n",
      "PassengerId          \n",
      "1006              1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"660\"\n",
       "            height=\"550\"\n",
       "            src=\"_plot_files/plots2.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f99fd04ed30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explain([1000,1006])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0_lbDj9X9-kH"
   },
   "source": [
    "## 5.\n",
    "train a second model (of any class, neural nets, linear, other boosting) and find an observation for which CP profiles are different between the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQPeuc1h60IQ"
   },
   "source": [
    "### Use scikit-learn random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtT3G16yxY-l"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as Model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cI9H-te5SQXa"
   },
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQN0E3tLxcl5"
   },
   "outputs": [],
   "source": [
    "model2 = Model2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCwmc7ESx31u"
   },
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "INtCCwWRx58t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_x, train_y.values[::,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EzRgvlQ7yKcw"
   },
   "source": [
    "### Check the second model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eGH-3eUIyMLz",
    "outputId": "4df7959b-8a17-4c45-a824-d83408c0a03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the second model: 0.8157894736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "test_pred = model2.predict(test_x)\n",
    "test_accuracy1 = accuracy_score(test_y, [round(value) for value in test_pred])\n",
    "print(\"Test accuracy of the second model: {}\".format(test_accuracy1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgb8CHMqoybc"
   },
   "source": [
    "### Find an observation for which CP profiles are different between the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer2 = Explainer(model2, variable_names=test_x.columns, data=test_x, y=test_y.columns, predict_function=lambda X: model2.predict_proba(X)[::,1], label=\"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gx6b7E7zprPK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real value:\n",
      "              Survived\n",
      "PassengerId          \n",
      "895               0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"660\"\n",
       "            height=\"550\"\n",
       "            src=\"_plot_files/plots3.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f99f9c3c668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real value:\n",
      "              Survived\n",
      "PassengerId          \n",
      "895               0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"660\"\n",
       "            height=\"550\"\n",
       "            src=\"_plot_files/plots4.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f99f9c4b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explain([895], model=model)\n",
    "explain([895], model=model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYmnCd-OwpW1"
   },
   "source": [
    "## 6.\n",
    "Comment on the results for points (4) and (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "npbIRR4-y638"
   },
   "source": [
    "4. CP profiles for different observations comparision\n",
    "\n",
    "    Given the selected two observations the model behaves very differently when looking at the \"Age\" parameter. For the first observation - a male in the third class whose fare is 8.7£, embarked in Southampton - there is a gap between the kids and the adults. The kids are very likely to survive and the adults will most likely die. There are some minor fluctuations, but those are almost negligible compared with the huge (bigger than 80%) \"adulthood gap\". On the other hand for the second observation - a female in the first class whose fare was 221.8£, embarked in the same city - the age do have a positive impact - those older than 30 almost certainly survived and younger people with the same other parameters are from ~10% up to ~20% more likely to die. It is strange for me that the model predicts that the very young children were more likely to die when having all other parameters as in the first observation then as in the second one. Those two observations have almost the same (with the respect to the translation) CP profile of the \"SibSp\" variable - the number of the siblings. The fare profiles are also different, but they do share the same property - the fare above £250 has the same impact as exactly £250. The differences in the \"Fare\" and \"Age\" CP profiles might be caused by the different classes of the two observations.\n",
    "\n",
    "5. Differences between CP profiles of the same observation for two models\n",
    "\n",
    "    Those two models predict very differently given the selected observation. The first model predict correctly and the second one does not. We can clearly see that the profile of the \"Age\" is much more reasonable for the first model and the second one might have overfitted - it has a few very strange and sharp edges. Note that the selected observation is from the test part of data (not the training one) so the overfitting would have negative impact on the accuracy of this prediction. Also the second model is convinced that having no siblings impact the probability of survival for this person positively. It might be a case, but so big difference between 0 and different number of siblings still looks alarming (of course the model might have found some strong dependency which was not noticed by the first model, but the accuracy hints us that it is not the case). The fluctuations of the \"Fare\" profile for the second modle also might mean that these is some overfitting, but still that \"Age\" profile is the strangest one."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1k5yb_LDQ0UO",
    "c4_HSH1NZs4s",
    "NLkKLWma9wWn",
    "izJSfphJ94V-",
    "HuVgwX6GR6Fh",
    "8m1RThxnR8eQ",
    "aT8Ht9m2R-sL",
    "t38TV1R4U_9N",
    "qdOzt1DKVCzP"
   ],
   "name": "titanic_v4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
