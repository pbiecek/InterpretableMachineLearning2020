{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyjaśnialne uczenie maszynowe – praca domowa 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Katarzyna Koprowska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystanym zbirem danych jest Home Equity (HMEQ), zawierający informacje o 5960 klientach banku, którzy otrzymali kredyty hipoteczne.\n",
    "\n",
    "Na podstawie zbioru próbowałam przewidzieć prawdopodobieństwo **defaultu**, czyli faktu, że klient będzie zalegał z płatnościami – określa to binarna zmienna **BAD** (1 oznacza default). Pozostałe 12 zmiennych opisuje m.in. historię kredytową aplikującego, historię zawodową oraz charakterystyki obecnej pożyczki. \n",
    "\n",
    "Więcej informacji na temat danych można znaleźć pod linkiem https://www.kaggle.com/ajay1735/hmeq-data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "hmeq = pd.read_csv(\"hmeq.csv\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "hmeq_info = {'BAD' : 'client defaulted on loan 0 = loan repaid',\n",
    "\"LOAN\" : \"Amount of the loan request\",\n",
    "\"MORTDUE\" : \"Amount due on existing mortgage\",\n",
    "\"VALUE\": \"Value of current property\",\n",
    "\"REASON\": \"DebtCon debt consolidation HomeImp = home improvement\",\n",
    "\"JOBS\" : \"occupational categories\",\n",
    "\"YOJ\": \"Years at present job\",\n",
    "\"DEROG\" : \"Number of major derogatory reports\",\n",
    "\"DELINQ\": \"Number of delinquent credit lines\",\n",
    "\"CLAGE\": \"Age of oldest trade line in months\",\n",
    "\"NINQ\": \"Number of recent credit lines\",\n",
    "\"CLNO\": \"Number of credit lines\",\n",
    "\"DEBTINC\" : \"Debt-to-income ratio\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przekształcenie danych nienumerycznych na *dummy variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "{column : is_numeric_dtype(hmeq[column]) for column in hmeq.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "set(hmeq['REASON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "set(hmeq['JOB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "hmeq = pd.concat([hmeq, pd.get_dummies(hmeq['REASON'], prefix='REASON', dummy_na=True)],axis=1)\n",
    "hmeq = pd.concat([hmeq, pd.get_dummies(hmeq['JOB'], prefix='JOB', dummy_na=True)],axis=1)\n",
    "hmeq.drop(['REASON', 'JOB'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Braki danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hmeq.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "hmeq_nonan = hmeq.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "X = hmeq_nonan.iloc[:, 1:]\n",
    "y = hmeq_nonan.loc[:, \"BAD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "for data in [X_train, X_test, X_val, y_train,  y_val, y_test]:\n",
    "    data.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "metrics = [\"accuracy_train\", \"accuracy_test\", \"roc_auc_train\", \"roc_auc_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model – las losowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "rf_final1 = pickle.load(open(\"final_nonan_rf.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprawdzenie na zbiorze testowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "results = {metric : {} for metric in [\"accuracy_test\", \"roc_auc_test\"]}\n",
    "results[\"accuracy_test\"][\"RandomForest\"] = (accuracy_score(y_test, rf_final1.predict(X_test)))\n",
    "results[\"roc_auc_test\"][\"RandomForest\"] = (roc_auc_score(y_test, rf_final1.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyjaśnianie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2. for some selected observation from this dataset, calculate the model predictions for model (1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "ind = 6\n",
    "obs = pd.DataFrame(X_test.iloc[ind, :]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "y_test[obs.index].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_final1.predict_proba(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3. for an observation selected in (2), calculate the decomposition of model prediction using Ceteris paribus / ICE profiles (packages for R: DALEX, ALEPlot, ingredients, packages for python: pyCeterisParibus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=list(X_train.columns), class_names=[\"GOOD\",\"BAD\"])\n",
    "explainer_discretize = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=list(X_train.columns), class_names=[\"GOOD\",\"BAD\"], discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_train.values[ind], rf_final1.predict_proba)\n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowe wyjaśnienie metodą **Ceteris Paribus** (najważniejsze zmienne wg **LIME**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import ceteris_paribus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from ceteris_paribus.explainer import explain\n",
    "from ceteris_paribus.plots.plots import plot_notebook\n",
    "from ceteris_paribus.profiles import individual_variable_profile\n",
    "from ceteris_paribus.plots.plots import plot\n",
    "from ceteris_paribus.explainer import explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_explainer = explain(rf_final1, X_test.columns, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cp = individual_variable_profile(cp_explainer, X_test.iloc[ind], y_test.iloc[ind])\n",
    "plot_notebook(cp, selected_variables=[\"DEBTINC\", \"DEROG\", \"CLAGE\", \"DELINQ\", \"REASON_nan\"], print_observations=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4. find two observations in the data set, such that they have different CP profiles (e.g. model response is growing with age for one observations and lowering with age for another). Note that you need to have model with interactions to have such differences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(45)\n",
    "ind_good = np.random.randint(len(y_test[y_test==0]), size=5)\n",
    "np.random.seed(45)\n",
    "ind_bad = np.random.randint(len(y_test[y_test==1]), size=5)\n",
    "obs_indexes = y_test[y_test[y_test==0].index[ind_good]].index.tolist()+ y_test[y_test[y_test==1].index[ind_bad]].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obs_indexes)\n",
    "obs_indexes = [457, 24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME i Ceteris Paribus dla lasów losowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in obs_indexes:\n",
    "    exp = explainer.explain_instance(X_test.values[i], rf_final1.predict_proba)\n",
    "    exp.show_in_notebook(show_table=True, show_all=False)\n",
    "    cp = individual_variable_profile(cp_explainer, X_test.iloc[i], y_test.iloc[i])\n",
    "    plot_notebook(cp, selected_variables=list(X_test.columns), print_observations=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5. train a second model (of any class, neural nets, linear, other boosting) and find an observation for which CP profiles are different between the models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth=7),n_estimators=150, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {metric : {} for metric in [\"accuracy_test\", \"roc_auc_test\"]}\n",
    "results[\"accuracy_test\"][\"RandomForest\"] = (accuracy_score(y_test, rf_final1.predict(X_test)))\n",
    "results[\"roc_auc_test\"][\"RandomForest\"] = (roc_auc_score(y_test, rf_final1.predict_proba(X_test)[:,1]))\n",
    "results[\"accuracy_test\"][\"AdaBoost\"] = (accuracy_score(y_test, adaboost.predict(X_test)))\n",
    "results[\"roc_auc_test\"][\"AdaBoost\"] = (roc_auc_score(y_test, adaboost.predict_proba(X_test)[:,1]))\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_good, ind_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_explainer_adaboost = explain(adaboost, X_test.columns, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "ind_good = np.random.randint(len(y_test[y_test==0]), size=5)\n",
    "np.random.seed(42)\n",
    "ind_bad = np.random.randint(len(y_test[y_test==1]), size=5)\n",
    "obs_indexes = y_test[y_test[y_test==0].index[ind_good]].index.tolist()+ y_test[y_test[y_test==1].index[ind_bad]].index.tolist()\n",
    "obs_indexes=[obs_indexes[5], obs_indexes[8]]\n",
    "obs_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME i Ceteris Paribus dla AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in obs_indexes:\n",
    "    exp = explainer.explain_instance(X_test.values[i], adaboost.predict_proba)\n",
    "    exp.show_in_notebook(show_table=True, show_all=False)\n",
    "    cp = individual_variable_profile(cp_explainer_adaboost, X_test.iloc[i], y_test.iloc[i])\n",
    "    plot_notebook(cp, selected_variables=list(X_test.columns), print_observations=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
